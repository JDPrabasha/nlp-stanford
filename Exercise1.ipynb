{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XbHD7xd3R8pp",
        "outputId": "6fbc66a1-aec2-4d2a-e20d-e95990650442"
      },
      "outputs": [],
      "source": [
        "\n",
        "from gensim.models import KeyedVectors \n",
        "from gensim.test.utils import datapath \n",
        "import pprint\n",
        "import matplotlib.pyplot as plt \n",
        "plt.rcParams['figure.figsize'] = [10, 5] \n",
        "# ----------------"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package reuters to\n",
            "[nltk_data]     /Users/dulajprabasha/nltk_data...\n",
            "[nltk_data]   Package reuters is already up-to-date!\n"
          ]
        }
      ],
      "source": [
        "import nltk\n",
        "import ssl\n",
        "\n",
        "try:\n",
        "    _create_unverified_https_context = ssl._create_unverified_context\n",
        "except AttributeError:\n",
        "    pass\n",
        "else:\n",
        "    ssl._create_default_https_context = _create_unverified_https_context\n",
        "\n",
        "nltk.download('reuters') #to specify download location, optionally add the argument: download_dir='/specify/desired/path/' from nltk.corpus import reuters\n",
        "import numpy as np\n",
        "import random\n",
        "import scipy as sp\n",
        "from sklearn.decomposition import TruncatedSVD \n",
        "from sklearn.decomposition import PCA\n",
        "START_TOKEN = '<START>' \n",
        "END_TOKEN = '<END>'\n",
        "np.random.seed(0) \n",
        "random.seed(0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RJjfsjULUpf1",
        "outputId": "02688741-66ed-4964-f413-b22df709614e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "unzip:  cannot find or open /root/nltk_data/corpora/reuters.zip, /root/nltk_data/corpora/reuters.zip.zip or /root/nltk_data/corpora/reuters.zip.ZIP.\n"
          ]
        }
      ],
      "source": [
        "!unzip /root/nltk_data/corpora/reuters.zip -d /root/nltk_data/corpora"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "kmcNFj6jWVuJ"
      },
      "outputs": [],
      "source": [
        "from nltk.corpus import reuters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "AFaDkStiS6oZ"
      },
      "outputs": [],
      "source": [
        "def read_corpus(category=\"grain\"):\n",
        "    \"\"\" Read files from the specified Reuter's category.\n",
        "        Params:\n",
        "            category (string): category name\n",
        "        Return:\n",
        "            list of lists, with words from each of the processed files\n",
        "            \"\"\"\n",
        "    files = reuters.fileids(category)\n",
        "    return [[START_TOKEN] + [w.lower() for w in list(reuters.words(f))] + [END_TOKEN] for f in files]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YfWIIbUjTU0n",
        "outputId": "456c750b-0c2b-4cae-8315-bef856d00563"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[['<START>', 'china', 'daily', 'says', 'vermin', 'eat', '7', '-', '12', 'pct', 'grain', 'stocks',\n",
            "  'a', 'survey', 'of', '19', 'provinces', 'and', 'seven', 'cities', 'showed', 'vermin', 'consume',\n",
            "  'between', 'seven', 'and', '12', 'pct', 'of', 'china', \"'\", 's', 'grain', 'stocks', ',', 'the',\n",
            "  'china', 'daily', 'said', '.', 'it', 'also', 'said', 'that', 'each', 'year', '1', '.', '575',\n",
            "  'mln', 'tonnes', ',', 'or', '25', 'pct', ',', 'of', 'china', \"'\", 's', 'fruit', 'output', 'are',\n",
            "  'left', 'to', 'rot', ',', 'and', '2', '.', '1', 'mln', 'tonnes', ',', 'or', 'up', 'to', '30',\n",
            "  'pct', ',', 'of', 'its', 'vegetables', '.', 'the', 'paper', 'blamed', 'the', 'waste', 'on',\n",
            "  'inadequate', 'storage', 'and', 'bad', 'preservation', 'methods', '.', 'it', 'said', 'the',\n",
            "  'government', 'had', 'launched', 'a', 'national', 'programme', 'to', 'reduce', 'waste', ',',\n",
            "  'calling', 'for', 'improved', 'technology', 'in', 'storage', 'and', 'preservation', ',', 'and',\n",
            "  'greater', 'production', 'of', 'additives', '.', 'the', 'paper', 'gave', 'no', 'further',\n",
            "  'details', '.', '<END>'],\n",
            " ['<START>', 'thai', 'trade', 'deficit', 'widens', 'in', 'first', 'quarter', 'thailand', \"'\", 's',\n",
            "  'trade', 'deficit', 'widened', 'to', '4', '.', '5', 'billion', 'baht', 'in', 'the', 'first',\n",
            "  'quarter', 'of', '1987', 'from', '2', '.', '1', 'billion', 'a', 'year', 'ago', ',', 'the',\n",
            "  'business', 'economics', 'department', 'said', '.', 'it', 'said', 'janunary', '/', 'march',\n",
            "  'imports', 'rose', 'to', '65', '.', '1', 'billion', 'baht', 'from', '58', '.', '7', 'billion',\n",
            "  '.', 'thailand', \"'\", 's', 'improved', 'business', 'climate', 'this', 'year', 'resulted', 'in',\n",
            "  'a', '27', 'pct', 'increase', 'in', 'imports', 'of', 'raw', 'materials', 'and', 'semi', '-',\n",
            "  'finished', 'products', '.', 'the', 'country', \"'\", 's', 'oil', 'import', 'bill', ',', 'however',\n",
            "  ',', 'fell', '23', 'pct', 'in', 'the', 'first', 'quarter', 'due', 'to', 'lower', 'oil', 'prices',\n",
            "  '.', 'the', 'department', 'said', 'first', 'quarter', 'exports', 'expanded', 'to', '60', '.', '6',\n",
            "  'billion', 'baht', 'from', '56', '.', '6', 'billion', '.', 'export', 'growth', 'was', 'smaller',\n",
            "  'than', 'expected', 'due', 'to', 'lower', 'earnings', 'from', 'many', 'key', 'commodities',\n",
            "  'including', 'rice', 'whose', 'earnings', 'declined', '18', 'pct', ',', 'maize', '66', 'pct', ',',\n",
            "  'sugar', '45', 'pct', ',', 'tin', '26', 'pct', 'and', 'canned', 'pineapples', 'seven', 'pct', '.',\n",
            "  'products', 'registering', 'high', 'export', 'growth', 'were', 'jewellery', 'up', '64', 'pct',\n",
            "  ',', 'clothing', '57', 'pct', 'and', 'rubber', '35', 'pct', '.', '<END>'],\n",
            " ['<START>', 'sri', 'lanka', 'gets', 'usda', 'approval', 'for', 'wheat', 'price', 'food',\n",
            "  'department', 'officials', 'said', 'the', 'u', '.', 's', '.', 'department', 'of', 'agriculture',\n",
            "  'approved', 'the', 'continental', 'grain', 'co', 'sale', 'of', '52', ',', '500', 'tonnes', 'of',\n",
            "  'soft', 'wheat', 'at', '89', 'u', '.', 's', '.', 'dlrs', 'a', 'tonne', 'c', 'and', 'f', 'from',\n",
            "  'pacific', 'northwest', 'to', 'colombo', '.', 'they', 'said', 'the', 'shipment', 'was', 'for',\n",
            "  'april', '8', 'to', '20', 'delivery', '.', '<END>']]\n"
          ]
        }
      ],
      "source": [
        "reuters_corpus = read_corpus() \n",
        "pprint.pprint(reuters_corpus[:3], compact=True, width=100)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "5rgtjQxQWbz7"
      },
      "outputs": [],
      "source": [
        "def distinct_words(corpus):\n",
        "    \"\"\" Determine a list of distinct words for the corpus.\n",
        "        Params:\n",
        "            corpus (list of list of strings): corpus of documents\n",
        "        Return:\n",
        "            corpus_words (list of strings): sorted list of distinct words across the corpus\n",
        "            n_corpus_words (integer): number of distinct words across the corpus\n",
        "    \"\"\"\n",
        "    corpus_words = [] \n",
        "    n_corpus_words = -1\n",
        "    # ------------------\n",
        "    # Write your implementation here.\n",
        "    # ------------------\n",
        "    corpus_words = [y for x in corpus for y in x]\n",
        "    corpus_words = list(set(corpus_words))\n",
        "    corpus_words = sorted(corpus_words)\n",
        "    n_corpus_words = len(corpus_words)\n",
        "\n",
        "    return corpus_words, n_corpus_words"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xRjX9lt7Yo81",
        "outputId": "54368b1e-a209-4793-d72e-44e2bb0f7f02"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--------------------------------------------------------------------------------\n",
            "Passed All Tests!\n",
            "--------------------------------------------------------------------------------\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# Run this sanity check\n",
        "# Note that this not an exhaustive check for correctness.\n",
        "# ---------------------\n",
        "# Define toy corpus\n",
        "test_corpus = [\"{} All that glitters isn't gold {}\".format(START_TOKEN, END_TOKEN).split(\" \"), \"{} All's well that ends well {}\".format(START_TOKEN, END_TOKEN).split(\" \")]\n",
        "test_corpus_words, num_corpus_words = distinct_words(test_corpus)\n",
        "# Correct answers\n",
        "ans_test_corpus_words = sorted([START_TOKEN, \"All\", \"ends\", \"that\", \"gold\", \"All's\", \"glitters\", \"isn't\", \"well\", END_TOKEN]) \n",
        "ans_num_corpus_words = len(ans_test_corpus_words)\n",
        "# Test correct number of words\n",
        "assert(num_corpus_words == ans_num_corpus_words), \"Incorrect number of distinct words. Correct: {}. Yours: {}\".format(ans_num_corpus_words, num_corpus_words) # Test correct words\n",
        "assert (test_corpus_words == ans_test_corpus_words), \"Incorrect corpus_words.\\nCorrect: {}\\nYours:\".format(str(ans_test_corpus_words), str(test_corpus_words))\n",
        "# Print Success\n",
        "print (\"-\" * 80) \n",
        "print(\"Passed All Tests!\") \n",
        "print (\"-\" * 80)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "y3JZf6f_aJOq"
      },
      "outputs": [],
      "source": [
        "def compute_co_occurrence_matrix(corpus, window_size=4):\n",
        "    \"\"\" Compute co-occurrence matrix for the given corpus and window_size (default of 4).\n",
        "        Note: Each word in a document should be at the center of a window. Words near edges will have a smaller\n",
        "              number of co-occurring words.\n",
        "              For example, if we take the document \"<START> All that glitters is not gold <END>\" with window size of 4,\n",
        "              \"All\" will co-occur with \"<START>\", \"that\", \"glitters\", \"is\", and \"not\".\n",
        "        Params:\n",
        "            corpus (list of list of strings): corpus of documents\n",
        "            window_size (int): size of context window\n",
        "        Return:\n",
        "            M (a symmetric numpy matrix of shape (number of unique words in the corpus , number of unique words in the corpus)):\n",
        "\n",
        "    Co-occurence matrix of word counts.\n",
        "    The ordering of the words in the rows/columns should be the same as the ordering of the words given by the distinct_words function.\n",
        "word2ind (dict): dictionary that maps word to index (i.e. row/column number) for matrix M.\n",
        "    \"\"\"\n",
        "    words, n_words = distinct_words(corpus) \n",
        "    M = None\n",
        "    word2ind = {}\n",
        "# ------------------\n",
        "# Write your implementation here.\n",
        "# ------------------\n",
        "    return M, word2ind"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3.10.4 64-bit",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.4"
    },
    "vscode": {
      "interpreter": {
        "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
